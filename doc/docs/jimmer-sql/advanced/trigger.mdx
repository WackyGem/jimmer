---
sidebar_position: 1
title: Trigger
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Jimmer supports triggers, and users can listen to database changes.

:::tip
Triggers can notify not only changes of objects, but also changes of associations.
:::

## Trigger type

### Supported trigger types

- BinLog trigger
    
    This is the default trigger type, which does not affect the SQL generated by Jimmer itself, has high performance, events are triggered after the transaction is committed. 
    
    It can monitor database changes caused by any reason, including data and changes caused by non-Jimmer APIs. However, the database must support binlog.

- Transaction trigger

    This trigger does not require the database to support binlog, and events are triggered before the transaction is committed; 
    its mechanism and [The AT mode of Alibaba Seata](https://seata.io/en-us/docs/dev/mode/at-mode.html) are similar, 
    additional query statements will be generated during the modification process, 
    which has a certain impact on the modification performance, and only the changes of the database caused by the Jimmer API can be monitored.

The difference between the two triggers is as follows

||BinLog Trigger|Transaction Trigger|
|---|---|---|
|Notification timing|After Transaction Commit|Before Transaction Commit|
|Performance|High|Low|
|Monitorable database changes|Database changes caused by any reason|Database changes caused only by the current application calling the Jimmer API|
|Database requirements|Supported and binlog enabled|No special requirements|
|Mechanism|Using third-party technology to push database binlog changes to the message queue, Jimmer application listens to the message queue|Any modification operation API of Jimmer automatically implants additional SQL queries to find data changes, similar to [The AT mode of Alibaba Seata](https://seata.io/en-us/docs/dev/mode/at-mode.html)|

Aside from the differences in this table, both triggers provide the same notification data to the user.

### Recommended usage

-   BinLog Trigger

    BinLog triggers is triggered after transaction is committed, in the face of a given fact that cannot be changed.
    
    That is, the BinLog trigger has no effect on the original transaction and is allowed to perform time-consuming operations. So it is suitable to perform multiple tasks in its processing logic, especially these tasks

    - Cache consistency maintenance
    - Heterogeneous data source synchronization
    - Send messages to other microservices asynchronously

-   Transaction Trigger

    The transaction trigger is triggered before the transaction is committed, and its processing logic is directly embedded in the current transaction.
    
    If its event processing logic throws exception, the current business modification will fail; if its processing logic cannot be completed quickly, the current transaction will not release resources for a long time.

    Therefore, transaction triggers are suitable for appending more behaviors to the current transaction without breaking atomicity.
    
    Especially suitable for use with [save-command](../mutation/save-command). save-command saves arbitrarily complex data structures and is a very black-boxed high-level API; transaction triggers can add some detailed monitoring and related redundant data linkage behaviors to save-command.

## Configure trigger type

Before discussing setting trigger types, let's look at how developers use triggers

-   `sqlClient.getTriggers()` or `sqlClient.getTriggers(false)`:
    The BinLog trigger object is returned first, if not, the Transaction trigger object is returned.

-   `sqlClient.getTriggers(true)`:
    Explicitly returns the Transaction trigger, if there is no transaction trigger object, throws an exception.

In order to affect the result object that users can obtain through `sqlClient.getTriggers`, 
`TriggerType` can be configured when building SqlClient:

<Tabs groupId="language">
<TabItem value="java" label="Java">

```java
javax.sql.DataSource dataSource = ...;

JSqlClient sqlClient = JSqlClient
    .newBuilder()
    .setEntityManager(
        new EntityManager(classLoader, packageName)
    )
    // highlight-next-line
    .setTriggerType(TriggerType.BOTH)
    .builde();
```

</TabItem>
<TabItem value="kotlin" label="Kotlin">

```kotlin
javax.sql.DataSource dataSource = ...;

var sqlClient = newKSqlClient {
    setEntityManager(
        EntityManager(classLoader, packageName)
    )
    // highlight-next-line
    setTriggerType(TriggerType.BOTH)
}
```

</TabItem>
</Tabs>

Among them, `setEntityManager` is the premise of using trigger, and `setTriggerType` is used to configure trigger type, its argument has three values

-   BINLOG_ONLY:

    Only binlog trigger object is supported, which is the default configuration.
    - `sqlClient.getTriggers()` and `sqlClient.getTriggers(false)` return BinLog trigger objects.
    - `sqlClient.getTriggers(true)` will throw exception.

-   TRANSACTION_ONLY:

    Only transaction trigger object is supported.
    Returns the same transaction trigger object regardless of the argument of `sqlClient.getTriggers`.

-   BOTH:

    Both binLog triggers and transaction triggers are supported.
    - `sqlClient.getTriggers()` and `sqlClient.getTriggers(false)` return binlog trigger objects
    - `sqlClient.getTriggers(true)` returns the transaction trigger object

Here, a table is used to compare the three cases

<table>
    <thead>
        <tr>
            <th></th>
            <th>getTriggers(false)</th>
            <th>getTriggers(true)</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>BINLOG_ONLY</td>
            <td>Binlog trigger api object</td>
            <td><span style={{color:'red'}}>Throws exception</span></td>
        </tr>
        <tr>
            <td>TRANSACTION_ONLY</td>
            <td colspan="2"><center><b>Shared</b> trigger api object</center></td>
        </tr>
        <tr>
            <td>BOTH</td>
            <td>Binlog trigger api object</td>
            <td>Transaction trigger api object</td>
        </tr>
    </tbody>
</table>

-   **Q**: Why is `BINLOG_ONLY` default mode?

    **A**: Transaction triggers will implant additional SQL queries in all save behaviors to simulate triggers, which will affect performance and are not supported by default.

-   **Q**: Why do two trigger APIs share the same object in `TRANSACTION_ONLY` mode?

    **A**: Jimmer's built-in cache consistency mechanism uses `sqlClient.getTriggers(false)`, this behavior cannot be changed by developers.

    The purpose of this is to make the cache consistency mechanism dose not affect current transaction, cache can only be cleared after the transaction is committed. Therefore, the original transaction is not stretched, thus ending quickly releasing lock resources.

    However, not all database products support binlog. At this time, `getTriggers(false)` returns the transaction trigger object, pretending to be the binlog trigger object, and taking over the cache consistency maintenance work that should have been handled by the binlog trigger.

    That is, `TRANSACTION_ONLY` is designed for databases that do not support binlog, **this is the only reason to choose this mode**.

-   **Q**: In `BOTH` mode, there are two different trigger API objects, does it mean that any modification event has two opportunities to process?

    **A**: Yes, and this is an important feature.

    Unlike Jimmer's built-in cache consistency mechanism, which must be caused by `sqlClient.getTriggers(false)`; the user's business code does not have this restriction, and developers can freely decide whether a processing logic should be registered to `sqlClient.getTriggers(false)` or `sqlClient.getTriggers(true)`, or even registering with both.

    - If the developer's processing logic contains some data additional modifications, it must be in the atomic scope of the current transaction, it should be registered to `sqlClient.getTriggers(true)`

    - If the developer's processing logic does not need to participate in the current transaction, it should be registered to `sqlClient.getTriggers(false)`, so that the current transaction ends as soon as possible, and the lock resources are released as soon as possible

    - If the developer's processing logic contains both of the above two cases, the processing logic should be divided into two parts, and then should be registered to the two triggers respectively.

-   **Q**: For database that does not support binlog, is the cache consistency cleaning impossible to do after the transaction is committed?

    **A**: No, if the developer is willing to optimize, it can be done.

    It is true that this kind of database cannot support binlog triggers, and using transaction triggers to be receive the data change event during the transaction life cycle is the only feasible way.

    However, it is not necessary to perform cache cleanup immediately after receiving the notification, because the cleanup behavior of remote caches such as redis has network communication costs and the possibility of communication failure, doing so will cause local transactions to be prolonged or even fail.

    Jimmer's cache system supports custom `CacheOperator`. By customizing `CacheOperator`, users can override the cleanup behavior of the cache system, record the cache deletion task in ThreadLocal but not execute it immediately, and execute it after the transaction is committed.

    -   Practices that do not require reliability
        1. The custom `CacheOperator` uses `ThreadLocal` to record the cache keys to be deleted and does not execute it immediately.
        2. In Spring's `After commit` event, centrally clean up the cache.

    -   Practices that require reliability
        1. The custom `CacheOperator` uses `ThreadLocal` to record the cache keys to be deleted and does not execute it immediately.
        2. In Spring's `Before Commit` event, integrate the scattered records. A one-time insert into the local event table.
        3. In Spring's `After Commit` event, fetch data from the local event table, clear the cache, and if successful, delete the data from the local event table.
        4. Use a polling service to account for the failure of step 3.

## Enable BinLog trigger

Unlike tranaction trigger, binlog trigger need to use third-party technology to push database binlog changes to the message queue, and let the application listen to the message queue.

Therefore, it is not enough to specify the `TriggerType` as `BINLOG_ONLY` (also the default behavior) when building the SqlClient object.

There are many choices for message queues, such as `Kafka` and `RebbitMQ`; there are also many choices for third-party technologies that push database incremental binlogs to message queues, such as `MaxWell`, `Canal` and `DataBus`.

Jimmer places no restrictions on such choices. However, to simplify the discussion, this document assumes that `Kafka` is used for message queues and `Maxwell` is used for binlog push technology.

### Building the external environment

To use this feature, the following steps are required to build.

1. Select a database that supports binlog and enable the binlog function.
2. Install Kafka and create a topic.
3. Enable Maxwell and send binlog changes to the kafka topic created in the previous step.

You can click [here](https://github.com/babyfish-ct/jimmer/blob/main/example/env-with-cache/install.sh) to see the docker install script with the example.

### Monitor message queue

<Tabs groupId="language">
<TabItem value="java" label="Java">

```java
@Component
public class MaxwellListener {

    private static final ObjectMapper MAPPER = new ObjectMapper();

    private final Caches caches;

    public MaxwellListener(JSqlClient sqlClient) {
        this.caches = sqlClient.getCaches();
    }

    @KafkaListener(topics = "maxwell")
    public void onHandle(
            String json,
            Acknowledgment acknowledgment
    ) throws JsonProcessingException {
        JsonNode node = MAPPER.readTree(json);
        String tableName = node.get("table").asText();
        String type = node.get("type").asText();
        JsonNode data = node.get("data");
        switch (type) {
            case "insert":
                binLog.accept(tableName, null, data);
                break;
            case "update":
                binLog.accept(tableName, node.get("old"), data);
                break;
            case "delete":
                binLog.accept(tableName, data, null);
                break;
        }
        acknowledgment.acknowledge();
    }
}
```

</TabItem>
<TabItem value="kotlin" label="Kotlin">

```kotlin
@Component
class MaxwellListener(sqlClient: KSqlClient) {

    private val caches: KCaches = sqlClient.caches

    @KafkaListener(topics = ["maxwell"])
    fun onHandle(
        json: String,
        acknowledgment: Acknowledgment
    ) {
        val node = MAPPER.readTree(json)
        val tableName = node["table"].asText()
        val type = node["type"].asText()
        val data = node["data"]
        when (type) {
            "insert" ->
                binLog.accept(tableName, null, data)
            "update" ->
                binLog.accept(tableName, node["old"], data)
            "delete" ->
                binLog.accept(tableName, data, null)
        }
        acknowledgment.acknowledge()
    }

    companion object {
        private val MAPPER = ObjectMapper()
    }
}
```

</TabItem>
</Tabs>

Among them, `sqlClient.binLog.accept` triggers events according to the binlog event of the message queue, developer only need to simply call this behavior.

## Use example

### Preparation

:::caution
- If you want to use the binlog trigger, you must enable the binlog function of the database and use the code in the previous section to monitor the message queue.
- If you want to use a transaction trigger, there is no need for any additional preparation work in succession.
:::

### Registration processing logic

<Tabs groupId="language">
<TabItem value="java" label="Java">

```java
sqlClient.getTriggers().addEntityListener(Book.class, e -> {
    System.out.println("The object `Book` is changed");
    System.out.println("\told: " + e.getOldEntity());
    System.out.println("\tnew: " + e.getNewEntity());
});
sqlClient.getTriggers().addAssociationListener(BookProps.STORE, e -> {
    System.out.println("The many-to-one association `Book.store` is changed");
    System.out.println("\tbook id: " + e.getSourceId());
    System.out.println("\tdetached book store id: " + e.getDetachedTargetId());
    System.out.println("\tattached book store id: " + e.getAttachedTargetId());
});
sqlClient.getTriggers().addAssociationListener(BookStoreProps.BOOKS, e -> {
    System.out.println("The one-to-many association `BookStore.books` is changed");
    System.out.println("\tbook store id: " + e.getSourceId());
    System.out.println("\tdetached book id: " + e.getDetachedTargetId());
    System.out.println("\tattached book id: " + e.getAttachedTargetId());
});
```

</TabItem>
<TabItem value="kotlin" label="Kotlin">

```kotlin
sqlClient.triggers.addEntityListener(Book::class) {
    println("The object `Book` is changed");
    println("\told: ${it.oldEntity}");
    println("\tnew: ${it.newEntity}");
}
sqlClient.triggers.addAssociationListener(Book::store) {
    println("The many-to-one association `Book.store` is changed");
    println("\tbook id: ${it.sourceId}");
    println("\tdetached book store id: ${it.detachedTargetId}");
    println("\tattached book store id: ${it.attachedTargetId}");
}
sqlClient.triggers.addAssociationListener(BookStore::books) {
    println("The one-to-many association `BookStore.books` is changed");
    println("\tbook store id: ${it.sourceId}");
    println("\tdetached book id: ${it.detachedTargetId}");
    println("\tattached book id: ${it.attachedTargetId}");
}
```

</TabItem>
</Tabs>

Where `sqlClient.getTriggers()` or `sqClient.triggers` is used to register the processing logic to the default triggers.

You can also replace `sqlClient.getTriggers()` or `sqClient.triggers` in the above code with **`sqlClient.getTriggers(true)`**, so that the processing logic is registered to the Transaction trigger.

### Experience triggers

BinLog trigger object can monitor database changes for any reason, and can send events to even if the database is modified by any other means bypassing the application.

For example, you can directly use SQL tools to execute

```sql
update BOOK set STORE_ID = 2 where ID = 7;
```

However, if you want to send events to transaction trigger object, database can only be modified the database through Jimmer's API, e.g.

<Tabs groupId="language">
<TabItem value="java" label="Java">

```java
BookTable book = BookTable.$;
sqlClient
        .createUpdate(book)
        .set(book.store().id(), 2L)
        .where(book.id().eq(7L))
        .execute();
```

</TabItem>
<TabItem value="kotlin" label="Kotlin">

```kotlin
sqlClient
        .createUpdate(Book::class) {
            set(table.store.id, 2L)
            where(table.id eq 7L)
        }
        .execute()
```

</TabItem>
</Tabs>

Output result

```
The object `Book` is changed
	old: {"id":7,"name":"Programming TypeScript","edition":1,"price":47.50,"store":{"id":1}}
	new: {"id":7,"name":"Programming TypeScript","edition":1,"price":47.50,"store":{"id":2}}
The many-to-one association `Book.store` is changed
	book id: 7
	detached book store id: 1
	attached book store id: 2
The one-to-many association `BookStore.books` is changed
	book store id: 1
	detached book id: 7
	attached book id: null
The one-to-many association `BookStore.books` is changed
	book store id: 2
	detached book id: null
	attached book id: 7
```